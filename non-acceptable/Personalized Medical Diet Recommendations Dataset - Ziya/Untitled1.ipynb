{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90966940-991e-407d-96cd-827cc8b2d89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble Balanced Accuracy: 0.23027266122303724\n",
      "Macro F1-Score: 0.2134778873377931\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.27      0.25       248\n",
      "           1       0.23      0.12      0.16       259\n",
      "           2       0.27      0.45      0.34       282\n",
      "           3       0.17      0.08      0.11       211\n",
      "\n",
      "    accuracy                           0.24      1000\n",
      "   macro avg       0.22      0.23      0.21      1000\n",
      "weighted avg       0.23      0.24      0.22      1000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 67  40 114  27]\n",
      " [ 73  32 124  30]\n",
      " [ 88  42 126  26]\n",
      " [ 70  27  97  17]]\n",
      "\n",
      "Feature Importance (Top 10):\n",
      "                    Feature  Importance\n",
      "1               Daily_Steps    3.098077\n",
      "2         Cholesterol_Level    2.935792\n",
      "0            Caloric_Intake    2.876690\n",
      "4            Protein_Intake    2.832074\n",
      "8   Blood_Pressure_Systolic    2.697610\n",
      "5                Fat_Intake    2.661577\n",
      "9         Blood_Sugar_Level    2.656062\n",
      "3       Carbohydrate_Intake    2.640308\n",
      "7                       Age    2.495276\n",
      "10              Sleep_Hours    2.428009\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Personalized_Diet_RecommendationsDC.csv\")\n",
    "\n",
    "# Define top 15 features based on average importance\n",
    "selected_features = [\n",
    "    'Caloric_Intake', 'Daily_Steps', 'Cholesterol_Level', 'Carbohydrate_Intake',\n",
    "    'Protein_Intake', 'Fat_Intake', 'BMI', 'Age', 'Blood_Pressure_Systolic',\n",
    "    'Blood_Sugar_Level', 'Sleep_Hours', 'Weight_kg', 'Food_Aversions_Sweet',\n",
    "    'Height_cm', 'Dietary_Habits_Vegan'\n",
    "]\n",
    "X = df[selected_features]\n",
    "y = df['Recommended_Meal_Plan']\n",
    "\n",
    "# Define numeric columns for scaling\n",
    "numeric_cols = [\n",
    "    'Caloric_Intake', 'Daily_Steps', 'Cholesterol_Level', 'Carbohydrate_Intake',\n",
    "    'Protein_Intake', 'Fat_Intake', 'BMI', 'Age', 'Blood_Pressure_Systolic',\n",
    "    'Blood_Sugar_Level', 'Sleep_Hours', 'Weight_kg', 'Height_cm'\n",
    "]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# Define base models with hyperparameter grids\n",
    "catboost = CatBoostClassifier(verbose=0, random_state=42)\n",
    "catboost_grid = {\n",
    "    'iterations': [500, 1000],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'depth': [6, 8]\n",
    "}\n",
    "catboost_search = GridSearchCV(catboost, catboost_grid, cv=3, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "xgboost = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "xgboost_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 6]\n",
    "}\n",
    "xgboost_search = GridSearchCV(xgboost, xgboost_grid, cv=3, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "rf_search = GridSearchCV(rf, rf_grid, cv=3, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Define stacking ensemble\n",
    "estimators = [\n",
    "    ('catboost', catboost_search),\n",
    "    ('xgboost', xgboost_search),\n",
    "    ('rf', rf_search)\n",
    "]\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(multi_class='multinomial', max_iter=1000),\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "# Train stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"Stacking Ensemble Balanced Accuracy:\", balanced_acc)\n",
    "print(\"Macro F1-Score:\", macro_f1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Feature Importance (average from base models)\n",
    "catboost_importance = stacking_model.named_estimators_['catboost'].best_estimator_.get_feature_importance()\n",
    "xgboost_importance = stacking_model.named_estimators_['xgboost'].best_estimator_.feature_importances_\n",
    "rf_importance = stacking_model.named_estimators_['rf'].best_estimator_.feature_importances_\n",
    "avg_importance = (catboost_importance + xgboost_importance + rf_importance) / 3\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': avg_importance\n",
    "})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance (Top 10):\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Save model and scaler\n",
    "#joblib.dump(stacking_model, \"stacking_classifier_model.pkl\")\n",
    "#joblib.dump(scaler, \"scaler_stacking.pkl\")\n",
    "#print(\"\\nModel saved as 'stacking_classifier_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
